{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9853b28-d4a2-4b89-a1eb-31ef81db5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as l\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    MBart50TokenizerFast,\n",
    "    MBartForConditionalGeneration,\n",
    "    MBartTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c016c-5e24-497f-a4c5-363cd33cecf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa3896-55c0-428b-b767-50670d6115cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8372bd0-2e17-471a-a4a7-1d19d75c2ba9",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4639c-a650-41cb-84a7-667dad62f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437a672-efcd-4c71-a310-aec46aab540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb3e67c-6f21-4d9e-a0dd-caf3022ca203",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Incorrect sentence: Whats I do? Correct Sentence:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afea27-3447-48ac-bfd0-5637d75f5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6f3d9-83b4-4341-9ed2-693c022cc3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    # max_length=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f42199-cb73-46ac-a398-eaaaccd70135",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = tokenizer.batch_decode(gen_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fee45d-a69f-4e18-9dfd-6c476407aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Incorrect sentence: Whats I do? Correct Sentence: 13 May 2007 (19:16:'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80909051-fa75-477c-87d8-026d6bc86bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e527c1f7-2082-49a6-b19f-bbcdad3d067b",
   "metadata": {},
   "source": [
    "## Seq to Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa825a4-55ff-4f4f-bdf5-72aafbb16035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_s2s = MBartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    ")\n",
    "tokenizer_s2s = MBart50TokenizerFast.from_pretrained(\n",
    "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf139c-1ce5-4f83-99ac-2ebaf4bf7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_s2s.generation_config.pad_token_ids = tokenizer_s2s.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dbe11-8fb5-4451-aaea-ce75107828ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_s2s.lang_code_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cde05b-e09b-4201-8693-3dd0aafc7581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250004"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_s2s.lang_code_to_id[\"en_XX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1626522-5827-4efe-9964-5bef569fa158",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Incorrect sentence: Whats I do? Correct Sentence:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde4513-141a-4583-b970-0053c22aad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer_s2s(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f0c9c-2d90-4e98-b079-d6e44d891f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_tokens = model_s2s.generate(\n",
    "    **inputs, decoder_start_token_id=tokenizer_s2s.lang_code_to_id[\"en_XX\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df003ae-54e5-439c-9808-d4cd09e1452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whats I do? Correct sentence:'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_s2s.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff908ad-74ec-499d-a854-469437881ae9",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c1104-6c14-49e2-b1bb-9fae00618020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5655a6a6fa4e18a2c9fc77a1596d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e06ee8de4bd4739824b92147121b63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eec1108b64a4c989c62aeec59b05300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b58282c26834fd6b1d86a6b68ef907f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bd60243a2f425c96908cb1c9da6b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17e9a1aee984977a5f01a06e2be493f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e65da-fca1-4cba-b71a-9eacdadee264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct the english: The houses is wonderful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(\"correct the english: The houses is wonderful.\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3a701-133d-4d50-b2bd-d5d45009bcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
